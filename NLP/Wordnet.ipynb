{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('plan.n.01'), Synset('program.n.02'), Synset('broadcast.n.02'), Synset('platform.n.02'), Synset('program.n.05'), Synset('course_of_study.n.01'), Synset('program.n.07'), Synset('program.n.08'), Synset('program.v.01'), Synset('program.v.02')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "syns=wordnet.synsets(\"program\")\n",
    "print(syns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plan.n.01\n"
     ]
    }
   ],
   "source": [
    "#synset\n",
    "print(syns[0].name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plan\n"
     ]
    }
   ],
   "source": [
    "#just the word\n",
    "print(syns[0].lemmas()[0].name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a series of steps to be carried out or goals to be accomplished\n"
     ]
    }
   ],
   "source": [
    "#defination\n",
    "print(syns[0].definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['they drew up a six-step plan', 'they discussed plans for a new bond issue']\n"
     ]
    }
   ],
   "source": [
    "#examples\n",
    "print(syns[0].examples())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synonym and Antonym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('good.n.01'), Synset('good.n.02'), Synset('good.n.03'), Synset('commodity.n.01'), Synset('good.a.01'), Synset('full.s.06'), Synset('good.a.03'), Synset('estimable.s.02'), Synset('beneficial.s.01'), Synset('good.s.06'), Synset('good.s.07'), Synset('adept.s.01'), Synset('good.s.09'), Synset('dear.s.02'), Synset('dependable.s.04'), Synset('good.s.12'), Synset('good.s.13'), Synset('effective.s.04'), Synset('good.s.15'), Synset('good.s.16'), Synset('good.s.17'), Synset('good.s.18'), Synset('good.s.19'), Synset('good.s.20'), Synset('good.s.21'), Synset('well.r.01'), Synset('thoroughly.r.02')]\n"
     ]
    }
   ],
   "source": [
    "syns=wordnet.synsets(\"good\")\n",
    "print(syns)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Lemma('good.n.01.good')]\n",
      "[Lemma('good.n.02.good'), Lemma('good.n.02.goodness')]\n",
      "[Lemma('good.n.03.good'), Lemma('good.n.03.goodness')]\n",
      "[Lemma('commodity.n.01.commodity'), Lemma('commodity.n.01.trade_good'), Lemma('commodity.n.01.good')]\n",
      "[Lemma('good.a.01.good')]\n",
      "[Lemma('full.s.06.full'), Lemma('full.s.06.good')]\n",
      "[Lemma('good.a.03.good')]\n",
      "[Lemma('estimable.s.02.estimable'), Lemma('estimable.s.02.good'), Lemma('estimable.s.02.honorable'), Lemma('estimable.s.02.respectable')]\n",
      "[Lemma('beneficial.s.01.beneficial'), Lemma('beneficial.s.01.good')]\n",
      "[Lemma('good.s.06.good')]\n",
      "[Lemma('good.s.07.good'), Lemma('good.s.07.just'), Lemma('good.s.07.upright')]\n",
      "[Lemma('adept.s.01.adept'), Lemma('adept.s.01.expert'), Lemma('adept.s.01.good'), Lemma('adept.s.01.practiced'), Lemma('adept.s.01.proficient'), Lemma('adept.s.01.skillful'), Lemma('adept.s.01.skilful')]\n",
      "[Lemma('good.s.09.good')]\n",
      "[Lemma('dear.s.02.dear'), Lemma('dear.s.02.good'), Lemma('dear.s.02.near')]\n",
      "[Lemma('dependable.s.04.dependable'), Lemma('dependable.s.04.good'), Lemma('dependable.s.04.safe'), Lemma('dependable.s.04.secure')]\n",
      "[Lemma('good.s.12.good'), Lemma('good.s.12.right'), Lemma('good.s.12.ripe')]\n",
      "[Lemma('good.s.13.good'), Lemma('good.s.13.well')]\n",
      "[Lemma('effective.s.04.effective'), Lemma('effective.s.04.good'), Lemma('effective.s.04.in_effect'), Lemma('effective.s.04.in_force')]\n",
      "[Lemma('good.s.15.good')]\n",
      "[Lemma('good.s.16.good'), Lemma('good.s.16.serious')]\n",
      "[Lemma('good.s.17.good'), Lemma('good.s.17.sound')]\n",
      "[Lemma('good.s.18.good'), Lemma('good.s.18.salutary')]\n",
      "[Lemma('good.s.19.good'), Lemma('good.s.19.honest')]\n",
      "[Lemma('good.s.20.good'), Lemma('good.s.20.undecomposed'), Lemma('good.s.20.unspoiled'), Lemma('good.s.20.unspoilt')]\n",
      "[Lemma('good.s.21.good')]\n",
      "[Lemma('well.r.01.well'), Lemma('well.r.01.good')]\n",
      "[Lemma('thoroughly.r.02.thoroughly'), Lemma('thoroughly.r.02.soundly'), Lemma('thoroughly.r.02.good')]\n"
     ]
    }
   ],
   "source": [
    "for syn in syns:\n",
    "    print(syn.lemmas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good : \n",
      "good : evil\n",
      "goodness : evilness\n",
      "good : bad\n",
      "goodness : badness\n",
      "commodity : \n",
      "trade_good : \n",
      "good : \n",
      "good : bad\n",
      "full : \n",
      "good : \n",
      "good : evil\n",
      "estimable : \n",
      "good : \n",
      "honorable : \n",
      "respectable : \n",
      "beneficial : \n",
      "good : \n",
      "good : \n",
      "good : \n",
      "just : \n",
      "upright : \n",
      "adept : \n",
      "expert : \n",
      "good : \n",
      "practiced : \n",
      "proficient : \n",
      "skillful : \n",
      "skilful : \n",
      "good : \n",
      "dear : \n",
      "good : \n",
      "near : \n",
      "dependable : \n",
      "good : \n",
      "safe : \n",
      "secure : \n",
      "good : \n",
      "right : \n",
      "ripe : \n",
      "good : \n",
      "well : \n",
      "effective : \n",
      "good : \n",
      "in_effect : \n",
      "in_force : \n",
      "good : \n",
      "good : \n",
      "serious : \n",
      "good : \n",
      "sound : \n",
      "good : \n",
      "salutary : \n",
      "good : \n",
      "honest : \n",
      "good : \n",
      "undecomposed : \n",
      "unspoiled : \n",
      "unspoilt : \n",
      "good : \n",
      "well : ill\n",
      "good : \n",
      "thoroughly : \n",
      "soundly : \n",
      "good : \n"
     ]
    }
   ],
   "source": [
    "synonyms=[]\n",
    "antonyma=[]\n",
    "for syn in syns:\n",
    "    for l in syn.lemmas():\n",
    "        synonyms.append(l.name())\n",
    "        if l.antonyms():\n",
    "                antonyma.append(l.antonyms()[0].name())\n",
    "        else:\n",
    "            antonyma.append(\"\")\n",
    "for i in range(len(synonyms)):\n",
    "    print(\"%s : %s\"%(synonyms[i],antonyma[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9090909090909091\n"
     ]
    }
   ],
   "source": [
    "w1=wordnet.synset(\"boat.n.01\")\n",
    "w2=wordnet.synset(\"ship.n.01\")\n",
    "print(w1.wup_similarity(w2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6956521739130435\n"
     ]
    }
   ],
   "source": [
    "w1=wordnet.synset(\"boat.n.01\")\n",
    "w2=wordnet.synset(\"bike.n.01\")\n",
    "print(w1.wup_similarity(w2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2962962962962963\n"
     ]
    }
   ],
   "source": [
    "w1=wordnet.synset(\"boat.n.01\")\n",
    "w2=wordnet.synset(\"dolphin.n.01\")\n",
    "print(w1.wup_similarity(w2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
